{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOkpc/I5fGM4I6DavttZP2W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/japb11/tinyv4/blob/main/tiny.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1K9OMtaMpvj-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "11fb7f4b-bc95-4723-edf1-1228745735d8"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchsummary import summary\n",
        "from torchcontrib.optim import SWA\n",
        "\n",
        "_INPUT_SIZE = 416\n",
        "\n",
        "_ANCHORS = [(23, 27), (37, 58), (81, 82),\n",
        "            (81, 82), (135, 169), (344, 319)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-6ecbd2c279cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchsummary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSWA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0m_INPUT_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m416\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchcontrib'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6BRAVo182G5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c57c3133-9686-4025-eecb-173d5e96f942"
      },
      "source": [
        "#take a look at the kind of GPU we have\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Feb 22 23:39:00 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   70C    P0    31W /  70W |   3058MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_9WIWXdLITJ"
      },
      "source": [
        "class BasicConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1):\n",
        "        super(BasicConv, self).__init__()\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, kernel_size//2, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.activation = nn.LeakyReLU(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.activation(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5sTmjxKImGQ"
      },
      "source": [
        "class CSPBlock(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "      super(CSPBlock, self).__init__()\n",
        "      self.input_size = in_channels\n",
        "      \n",
        "      #DenseBlock\n",
        "      #->1x1 conv\n",
        "      #->3x3 conv\n",
        "      #Transition Layer\n",
        "      #->1 x 1 conv layer\n",
        "      #-> 2 x 2 pooling layer, S=2\n",
        "\n",
        "      self.conv_1 = BasicConv(in_channels, in_channels, 3, 1)\n",
        "      self.conv_2 = BasicConv(in_channels // 2, in_channels // 2, 3, 1)\n",
        "      self.conv_3 = BasicConv(in_channels // 2, in_channels // 2, 3, 1)\n",
        "      self.conv_4 = BasicConv(in_channels, in_channels, 1, 1)\n",
        "      self.maxpool = nn.MaxPool2d([2,2],[2,2])\n",
        "    \n",
        "    def forward(self, x):\n",
        "\n",
        "      size = self.input_size\n",
        "\n",
        "      x = self.conv_1(x)\n",
        "      \n",
        "      x_1 = x\n",
        "      \n",
        "      x_2 = torch.split(x, size // 2, 1)[1]\n",
        "      \n",
        "      \n",
        "      \n",
        "      x_2 = self.conv_2(x_2)\n",
        "      x_3 = x_2\n",
        "      #x_4 = torch.split(x_2, size // 2, 1)[1]\n",
        "\n",
        "      x_2 = self.conv_3(x_2)\n",
        "      \n",
        "      x_2 = torch.cat((x_2, x_3), 1)\n",
        "      \n",
        "      x_2 = self.conv_4(x_2)\n",
        "      \n",
        "      x = torch.cat((x_1, x_2), 1)\n",
        "      \n",
        "      x = self.maxpool(x)\n",
        "      \n",
        "      return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UTra271yi6j"
      },
      "source": [
        "class YOLO_head(nn.Module):\n",
        "  def __init__(self, in_channels, anchors, n_classes):\n",
        "    super(YOLO_head, self).__init__()\n",
        "    self.anchors = nn.Parameter(\n",
        "            torch.FloatTensor(anchors).view(-1, 1, 1, 2), requires_grad=False\n",
        "        )\n",
        "    self.num_anchors = len(anchors)\n",
        "    self.num_classes = n_classes\n",
        "    self.conv = nn.Conv2d(in_channels, self.num_anchors * (5 + self.num_classes), 1, 1, bias=False)\n",
        "\n",
        "  def forward(self, input, img_size):\n",
        "    \n",
        "    pred = self.conv(input)\n",
        "    \n",
        "    B = pred.size(0)\n",
        "    H = pred.size(2)\n",
        "    W = pred.size(3)\n",
        "    N = self.num_classes\n",
        "\n",
        "    stride = img_size[0] // H\n",
        "\n",
        "    grid_x = torch.arange(W, device=device).repeat(H, 1).to(torch.float)\n",
        "    grid_y = torch.arange(H, device=device).repeat(W, 1).t().to(torch.float)\n",
        "    grid = torch.stack([grid_x, grid_y], dim=2)\n",
        "    grid = grid.data\n",
        "    pred = pred.view(B, -1, N + 5, H, W)\n",
        "    pred = pred.permute(0, 1, 3, 4, 2)\n",
        "    xy, wh, box_conf, cls_conf = torch.split(pred, [2, 2, 1, N], dim=-1)\n",
        "\n",
        "    xy = stride * (torch.sigmoid(xy) + grid)\n",
        "    wh = torch.exp(wh) * self.anchors\n",
        "    boxes = torch.cat([xy, wh], dim=-1)\n",
        "    boxes = boxes.view(B, -1, 4)\n",
        "    box_conf = torch.sigmoid(box_conf).view(B, -1, 1)\n",
        "    cls_conf = torch.sigmoid(cls_conf).reshape(B, -1, N)\n",
        " \n",
        "    return torch.cat([boxes, box_conf, cls_conf], dim=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_XC2GJalrY5"
      },
      "source": [
        "#GFLv2 HEAD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gse9DzbMLFRh"
      },
      "source": [
        "# _________________\n",
        "# | Input 416x416 |\n",
        "# |_______________|\n",
        "#        |\n",
        "#   _____|____\n",
        "#   | conv_1 |\n",
        "#   |________|\n",
        "#   _____|____\n",
        "#   | conv_2 |\n",
        "#   |________|\n",
        "#   _____|____\n",
        "#   | cspb_1 |\n",
        "#   |________|\n",
        "#   _____|____        ________         ________        ________ \n",
        "#   | cspb_2 |-------|   cat  |-------| conv_6 |------| YOLO   |\n",
        "#   |________|       |________|       |________|      |________|\n",
        "#   _____|____        ____|____\n",
        "#   | cspb_3 |       | Upsample|\n",
        "#   |________|       |_________|\n",
        "#        |           |  conv_5 |\n",
        "#        |           |_________|\n",
        "#   _____|____        ____|____         ________        ________ \n",
        "#   | conv_3 |-------| conv_4  |-------| conv_7 |------| YOLO   |\n",
        "#   |________|       |_________|       |________|      |________|"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9Dj6_eZp4LQ"
      },
      "source": [
        "#Creating Class where it will be defined the tiny-YoloV4 architecture\n",
        "class tiny_YOLOV4(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(tiny_YOLOV4, self).__init__()\n",
        "\n",
        "    self.conv_1 = BasicConv(3, 32, 3, 2)\n",
        "    self.conv_2 = BasicConv(32, 64, 3, 2)\n",
        "\n",
        "    self.cspb_1 = CSPBlock(64)\n",
        "    self.cspb_2 = CSPBlock(128)\n",
        "\n",
        "    self.cspb_3 = CSPBlock(256)\n",
        "\n",
        "    self.conv_3 = BasicConv(512, 512, 3, 1)\n",
        "\n",
        "    self.conv_4 = BasicConv(512, 512, 3, 1)\n",
        "\n",
        "    \n",
        "    self.conv_5 = nn.Conv2d(512, 256, 1, 1)\n",
        "    self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "\n",
        "    self.conv_6 = BasicConv(512, 256, 3, 1)\n",
        "    self.conv_7 = BasicConv(512, 512, 3, 1)\n",
        "    self.yolo_1 = YOLO_head(256, _ANCHORS[:3] ,80)\n",
        "    self.yolo_2 = YOLO_head(512, _ANCHORS[-3:] ,80)\n",
        "    #self.conv_6 = BasicConv(512, 128, 1, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    input = x\n",
        "    x = self.conv_1(input)\n",
        "    x = self.conv_2(x)\n",
        "    x = self.cspb_1(x)\n",
        "    x = self.cspb_2(x)\n",
        "    x_1 = x\n",
        "    x = self.cspb_3(x)\n",
        "    x = self.conv_3(x)\n",
        "    x = self.conv_4(x)\n",
        "    x_2 = x\n",
        "    x = self.conv_5(x)\n",
        "    x = self.upsample(x)\n",
        "    \n",
        "    x_1 = torch.cat((x_1, x), 1)\n",
        "    x_1 = self.conv_6(x_1)\n",
        "    x_2 = self.conv_7(x_2)\n",
        "    yolo_res_1 = self.yolo_1(x_1, input.shape[-2:])\n",
        "    yolo_res_2 = self.yolo_2(x_2, input.shape[-2:])\n",
        "    return yolo_res_1, yolo_res_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07mwO_h5VUn9"
      },
      "source": [
        "#!gdown https://github.com/bubbliiiing/yolov4-tiny-pytorch/releases/download/v1.0/yolov4_tiny_weights_coco.pth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kbheq8yzqWTC",
        "outputId": "e94fcd51-79b1-4ff4-c678-652d51a34fc6"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = tiny_YOLOV4().to(device)\n",
        "summary(model, input_size=(3, 416, 416))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 208, 208]             864\n",
            "       BatchNorm2d-2         [-1, 32, 208, 208]              64\n",
            "         LeakyReLU-3         [-1, 32, 208, 208]               0\n",
            "         BasicConv-4         [-1, 32, 208, 208]               0\n",
            "            Conv2d-5         [-1, 64, 104, 104]          18,432\n",
            "       BatchNorm2d-6         [-1, 64, 104, 104]             128\n",
            "         LeakyReLU-7         [-1, 64, 104, 104]               0\n",
            "         BasicConv-8         [-1, 64, 104, 104]               0\n",
            "            Conv2d-9         [-1, 64, 104, 104]          36,864\n",
            "      BatchNorm2d-10         [-1, 64, 104, 104]             128\n",
            "        LeakyReLU-11         [-1, 64, 104, 104]               0\n",
            "        BasicConv-12         [-1, 64, 104, 104]               0\n",
            "           Conv2d-13         [-1, 32, 104, 104]           9,216\n",
            "      BatchNorm2d-14         [-1, 32, 104, 104]              64\n",
            "        LeakyReLU-15         [-1, 32, 104, 104]               0\n",
            "        BasicConv-16         [-1, 32, 104, 104]               0\n",
            "           Conv2d-17         [-1, 32, 104, 104]           9,216\n",
            "      BatchNorm2d-18         [-1, 32, 104, 104]              64\n",
            "        LeakyReLU-19         [-1, 32, 104, 104]               0\n",
            "        BasicConv-20         [-1, 32, 104, 104]               0\n",
            "           Conv2d-21         [-1, 64, 104, 104]           4,096\n",
            "      BatchNorm2d-22         [-1, 64, 104, 104]             128\n",
            "        LeakyReLU-23         [-1, 64, 104, 104]               0\n",
            "        BasicConv-24         [-1, 64, 104, 104]               0\n",
            "        MaxPool2d-25          [-1, 128, 52, 52]               0\n",
            "         CSPBlock-26          [-1, 128, 52, 52]               0\n",
            "           Conv2d-27          [-1, 128, 52, 52]         147,456\n",
            "      BatchNorm2d-28          [-1, 128, 52, 52]             256\n",
            "        LeakyReLU-29          [-1, 128, 52, 52]               0\n",
            "        BasicConv-30          [-1, 128, 52, 52]               0\n",
            "           Conv2d-31           [-1, 64, 52, 52]          36,864\n",
            "      BatchNorm2d-32           [-1, 64, 52, 52]             128\n",
            "        LeakyReLU-33           [-1, 64, 52, 52]               0\n",
            "        BasicConv-34           [-1, 64, 52, 52]               0\n",
            "           Conv2d-35           [-1, 64, 52, 52]          36,864\n",
            "      BatchNorm2d-36           [-1, 64, 52, 52]             128\n",
            "        LeakyReLU-37           [-1, 64, 52, 52]               0\n",
            "        BasicConv-38           [-1, 64, 52, 52]               0\n",
            "           Conv2d-39          [-1, 128, 52, 52]          16,384\n",
            "      BatchNorm2d-40          [-1, 128, 52, 52]             256\n",
            "        LeakyReLU-41          [-1, 128, 52, 52]               0\n",
            "        BasicConv-42          [-1, 128, 52, 52]               0\n",
            "        MaxPool2d-43          [-1, 256, 26, 26]               0\n",
            "         CSPBlock-44          [-1, 256, 26, 26]               0\n",
            "           Conv2d-45          [-1, 256, 26, 26]         589,824\n",
            "      BatchNorm2d-46          [-1, 256, 26, 26]             512\n",
            "        LeakyReLU-47          [-1, 256, 26, 26]               0\n",
            "        BasicConv-48          [-1, 256, 26, 26]               0\n",
            "           Conv2d-49          [-1, 128, 26, 26]         147,456\n",
            "      BatchNorm2d-50          [-1, 128, 26, 26]             256\n",
            "        LeakyReLU-51          [-1, 128, 26, 26]               0\n",
            "        BasicConv-52          [-1, 128, 26, 26]               0\n",
            "           Conv2d-53          [-1, 128, 26, 26]         147,456\n",
            "      BatchNorm2d-54          [-1, 128, 26, 26]             256\n",
            "        LeakyReLU-55          [-1, 128, 26, 26]               0\n",
            "        BasicConv-56          [-1, 128, 26, 26]               0\n",
            "           Conv2d-57          [-1, 256, 26, 26]          65,536\n",
            "      BatchNorm2d-58          [-1, 256, 26, 26]             512\n",
            "        LeakyReLU-59          [-1, 256, 26, 26]               0\n",
            "        BasicConv-60          [-1, 256, 26, 26]               0\n",
            "        MaxPool2d-61          [-1, 512, 13, 13]               0\n",
            "         CSPBlock-62          [-1, 512, 13, 13]               0\n",
            "           Conv2d-63          [-1, 512, 13, 13]       2,359,296\n",
            "      BatchNorm2d-64          [-1, 512, 13, 13]           1,024\n",
            "        LeakyReLU-65          [-1, 512, 13, 13]               0\n",
            "        BasicConv-66          [-1, 512, 13, 13]               0\n",
            "           Conv2d-67          [-1, 512, 13, 13]       2,359,296\n",
            "      BatchNorm2d-68          [-1, 512, 13, 13]           1,024\n",
            "        LeakyReLU-69          [-1, 512, 13, 13]               0\n",
            "        BasicConv-70          [-1, 512, 13, 13]               0\n",
            "           Conv2d-71          [-1, 256, 13, 13]         131,328\n",
            "         Upsample-72          [-1, 256, 26, 26]               0\n",
            "           Conv2d-73          [-1, 256, 26, 26]       1,179,648\n",
            "      BatchNorm2d-74          [-1, 256, 26, 26]             512\n",
            "        LeakyReLU-75          [-1, 256, 26, 26]               0\n",
            "        BasicConv-76          [-1, 256, 26, 26]               0\n",
            "           Conv2d-77          [-1, 512, 13, 13]       2,359,296\n",
            "      BatchNorm2d-78          [-1, 512, 13, 13]           1,024\n",
            "        LeakyReLU-79          [-1, 512, 13, 13]               0\n",
            "        BasicConv-80          [-1, 512, 13, 13]               0\n",
            "           Conv2d-81          [-1, 255, 26, 26]          65,280\n",
            "        YOLO_head-82             [-1, 2028, 85]               0\n",
            "           Conv2d-83          [-1, 255, 13, 13]         130,560\n",
            "        YOLO_head-84              [-1, 507, 85]               0\n",
            "================================================================\n",
            "Total params: 9,857,696\n",
            "Trainable params: 9,857,696\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.98\n",
            "Forward/backward pass size (MB): 201.66\n",
            "Params size (MB): 37.60\n",
            "Estimated Total Size (MB): 241.25\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lv_vA9UilnFq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "b44efc2d-38c9-43ad-a5a1-d9eb473673a3"
      },
      "source": [
        "#train the network\n",
        "class Trainer():\n",
        "  def __init__(self, ep_train = 100, ep_val, lr = 1e-1, wd = 1e-5):\n",
        "    self.num_epochs_train = ep_train\n",
        "    self.num_epochs_val = ep_val \n",
        "    self.lr = lr\n",
        "    self.wd = wd\n",
        "\n",
        "  def train(model):\n",
        "\n",
        "    \"\"\" define loss criterion \"\"\"\n",
        "    criterion = nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "    \"\"\" define optimizer \"\"\"\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=self.lr, weight_decay=1e-5)\n",
        "\n",
        "    \"\"\" define learning rate scheduler \"\"\"\n",
        "    scheduler = torch.optim.lr_scheduler.CyclicLRWithRestarts(optimizer, self.Batch_size, epoch_size, restart_period=5, t_mult=1.2, policy=\"cosine\")\n",
        "\n",
        "    \"\"\" define loss scaler for automatic mixed precision \"\"\"\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    \"\"\" define model and learning rate scheduler for stochastic weight averaging \"\"\"\n",
        "    swa_model = torch.optim.swa_utils.AveragedModel(model)\n",
        "    swa_scheduler = torch.optim.swa_utils.SWALR(optimizer, swa_lr=5e-5)\n",
        "\n",
        "\n",
        "    for epoch in range(100):\n",
        "          for input, target in loader:\n",
        "              optimizer.zero_grad()\n",
        "              loss_fn(model(input), target).backward()\n",
        "              optimizer.step()\n",
        "          if epoch > swa_start:\n",
        "              swa_model.update_parameters(model)\n",
        "              swa_scheduler.step()\n",
        "          else:\n",
        "              scheduler.step()\n",
        "\n",
        "    for input, target in loader:\n",
        "      optimizer.zero_grad()\n",
        "      loss_fn(model(input), target).backward()\n",
        "      optimizer.step()\n",
        "      if epoch > swa_start:\n",
        "          swa_model.update_parameters(model)\n",
        "          swa_scheduler.step()\n",
        "      else:\n",
        "          scheduler.step()\n",
        "\n",
        "\n",
        "    for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "  print('Finished Training')\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-c971c6da5efa>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    self.net =\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}